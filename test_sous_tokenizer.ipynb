{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e663c2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thepurposeofourlivesistobehappy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: model/tokenized_corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: model/sortie.txt\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 32000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 100000\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: model/tokenized_corpus.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 1 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=34\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=18\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 1 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 19 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 1\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 1\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 1 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=17 obj=89.488 num_tokens=32 num_tokens/piece=1.88235\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=17 obj=94.3869 num_tokens=32 num_tokens/piece=1.88235\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: model/sortie.txt.model\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Internal: src/trainer_interface.cc(590) [(trainer_spec_.vocab_size()) == (model_proto->pieces_size())] Vocabulary size too high (32000). Please set it to a value <= 22.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10522/1705221612.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mspm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenized_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(arg, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mSentencePieceTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_TrainFromMap2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mSentencePieceTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_TrainFromMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36m_TrainFromMap\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_TrainFromMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_sentencepiece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceTrainer__TrainFromMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Internal: src/trainer_interface.cc(590) [(trainer_spec_.vocab_size()) == (model_proto->pieces_size())] Vocabulary size too high (32000). Please set it to a value <= 22."
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "\n",
    "#textfile = \"inputText.txt\"\n",
    "textfile = \"test.txt\"\n",
    "\n",
    "corpus = open (textfile,encoding=\"utf-8\")\n",
    "\n",
    "model = \"model/sortie.txt\"\n",
    "\n",
    "content = corpus.readlines()\n",
    "#tok_corp = content[0].split()\n",
    "\n",
    "clean_content = re.sub('[^A-Za-z0-9]+', ' ', content[0])\n",
    "\n",
    "print(clean_content)\n",
    "\n",
    "#return a list\n",
    "#tok_corp = word_tokenize(content[0])\n",
    "tok_corp = word_tokenize(clean_content)\n",
    "\n",
    "#get the tokenized text as string\n",
    "toc = str(tok_corp).strip('[]')\n",
    "\n",
    "#saving tokenized text\n",
    "file = open('model/tokenized_corpus.txt', 'w')\n",
    "file.write(toc)\n",
    "file.close()\n",
    "\n",
    "tokenized_corpus = \"model/tokenized_corpus.txt\"\n",
    "\n",
    "\n",
    "spm.SentencePieceTrainer.train(input=tokenized_corpus, model_prefix = model, vocab_size = 32000, max_sentence_length=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78225243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Tokens Before BPE\n",
      "All tokens: dict_keys(['t', 'h', 'e', '</w>', 'i', 'n', 'r', 's', 'm', 'o', 'v', 'a', 'l', 'f', 'g', 'c', 'd', '.', 'p', 'y', 'u', '-', 'j', 'b', 'w', 'k', ',', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 96\n",
      "==========\n",
      "Iter: 0\n",
      "Best pair: ('e', '</w>')\n",
      "All tokens: dict_keys(['t', 'h', 'e</w>', 'i', 'n', 'e', 'r', 's', '</w>', 'm', 'o', 'v', 'a', 'l', 'f', 'g', 'c', 'd', '.', 'p', 'y', 'u', '-', 'j', 'b', 'w', 'k', ',', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 97\n",
      "==========\n",
      "Iter: 1\n",
      "Best pair: ('d', '</w>')\n",
      "All tokens: dict_keys(['t', 'h', 'e</w>', 'i', 'n', 'e', 'r', 's', '</w>', 'm', 'o', 'v', 'a', 'l', 'f', 'g', 'c', 'd</w>', 'd', '.', 'p', 'y', 'u', '-', 'j', 'b', 'w', 'k', ',', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 98\n",
      "==========\n",
      "Iter: 2\n",
      "Best pair: ('i', 'n')\n",
      "All tokens: dict_keys(['t', 'h', 'e</w>', 'in', 'e', 'r', 's', '</w>', 'm', 'o', 'v', 'a', 'l', 'f', 'g', 'c', 'n', 'd</w>', 'd', '.', 'p', 'y', 'i', 'u', '-', 'j', 'b', 'w', 'k', ',', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 99\n",
      "==========\n",
      "Iter: 3\n",
      "Best pair: ('s', '</w>')\n",
      "All tokens: dict_keys(['t', 'h', 'e</w>', 'in', 'e', 'r', 's', '</w>', 'm', 'o', 'v', 'a', 'l', 'f', 'g', 'c', 'n', 's</w>', 'd</w>', 'd', '.', 'p', 'y', 'i', 'u', '-', 'j', 'b', 'w', 'k', ',', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 100\n",
      "==========\n",
      "Iter: 4\n",
      "Best pair: ('t', 'h')\n",
      "All tokens: dict_keys(['th', 'e</w>', 'in', 't', 'e', 'r', 's', '</w>', 'm', 'o', 'v', 'a', 'l', 'f', 'g', 'c', 'n', 's</w>', 'h', 'd</w>', 'd', '.', 'p', 'y', 'i', 'u', '-', 'j', 'b', 'w', 'k', ',', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 101\n",
      "==========\n",
      "Iter: 5\n",
      "Best pair: ('a', 'n')\n",
      "All tokens: dict_keys(['th', 'e</w>', 'in', 't', 'e', 'r', 's', '</w>', 'm', 'o', 'v', 'a', 'l', 'f', 'g', 'c', 'n', 'an', 's</w>', 'h', 'd</w>', 'd', '.', 'p', 'y', 'i', 'u', '-', 'j', 'b', 'w', 'k', ',', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 102\n",
      "==========\n",
      "Iter: 6\n",
      "Best pair: ('t', 'i')\n",
      "All tokens: dict_keys(['th', 'e</w>', 'in', 't', 'e', 'r', 's', '</w>', 'm', 'o', 'v', 'a', 'l', 'f', 'g', 'c', 'n', 'an', 's</w>', 'h', 'd</w>', 'd', '.', 'p', 'y', 'ti', 'u', '-', 'j', 'i', 'b', 'w', 'k', ',', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 103\n",
      "==========\n",
      "Iter: 7\n",
      "Best pair: ('e', 'r')\n",
      "All tokens: dict_keys(['th', 'e</w>', 'in', 't', 'er', 'e', 's', '</w>', 'r', 'm', 'o', 'v', 'a', 'l', 'f', 'g', 'c', 'n', 'an', 's</w>', 'h', 'd</w>', 'd', '.', 'p', 'y', 'ti', 'u', '-', 'j', 'i', 'b', 'w', 'k', ',', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 104\n",
      "==========\n",
      "Iter: 8\n",
      "Best pair: ('o', 'n')\n",
      "All tokens: dict_keys(['th', 'e</w>', 'in', 't', 'er', 'e', 's', '</w>', 'r', 'm', 'o', 'v', 'a', 'l', 'f', 'g', 'c', 'on', 'an', 's</w>', 'h', 'd</w>', 'd', '.', 'p', 'y', 'ti', 'u', '-', 'n', 'j', 'i', 'b', 'w', 'k', ',', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 105\n",
      "==========\n",
      "Iter: 9\n",
      "Best pair: ('e', 'n')\n",
      "All tokens: dict_keys(['th', 'e</w>', 'in', 't', 'er', 'e', 's', '</w>', 'r', 'm', 'o', 'v', 'a', 'l', 'f', 'g', 'c', 'on', 'an', 's</w>', 'h', 'd</w>', 'd', '.', 'p', 'y', 'ti', 'u', '-', 'n', 'j', 'i', 'b', 'en', 'w', 'k', ',', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 106\n",
      "==========\n",
      "Iter: 10\n",
      "Best pair: ('o', 'r')\n",
      "All tokens: dict_keys(['th', 'e</w>', 'in', 't', 'er', 'e', 's', '</w>', 'r', 'm', 'o', 'v', 'a', 'l', 'f', 'g', 'c', 'on', 'an', 's</w>', 'h', 'd</w>', 'd', '.', 'p', 'y', 'ti', 'u', '-', 'n', 'j', 'i', 'b', 'en', 'w', 'or', 'k', ',', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 107\n",
      "==========\n",
      "Iter: 11\n",
      "Best pair: (',', '</w>')\n",
      "All tokens: dict_keys(['th', 'e</w>', 'in', 't', 'er', 'e', 's', '</w>', 'r', 'm', 'o', 'v', 'a', 'l', 'f', 'g', 'c', 'on', 'an', 's</w>', 'h', 'd</w>', 'd', '.', 'p', 'y', 'ti', 'u', '-', 'n', 'j', 'i', 'b', 'en', 'w', 'or', 'k', ',</w>', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 108\n",
      "==========\n",
      "Iter: 12\n",
      "Best pair: ('r', 'e')\n",
      "All tokens: dict_keys(['th', 'e</w>', 'in', 't', 'er', 'e', 's', '</w>', 're', 'm', 'o', 'v', 'a', 'l', 'f', 'g', 'c', 'on', 'an', 's</w>', 'h', 'd</w>', 'd', '.', 'p', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'i', 'b', 'en', 'w', 'or', 'k', ',</w>', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 109\n",
      "==========\n",
      "Iter: 13\n",
      "Best pair: ('a', 'l')\n",
      "All tokens: dict_keys(['th', 'e</w>', 'in', 't', 'er', 'e', 's', '</w>', 're', 'm', 'o', 'v', 'al', 'f', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 'd</w>', 'l', 'd', '.', 'p', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'i', 'b', 'en', 'w', 'or', 'k', ',</w>', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 110\n",
      "==========\n",
      "Iter: 14\n",
      "Best pair: ('th', 'e</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 's', '</w>', 're', 'm', 'o', 'v', 'al', 'f', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 'd</w>', 'l', 'd', '.', 'p', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'i', 'e</w>', 'th', 'b', 'en', 'w', 'or', 'k', ',</w>', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 111\n",
      "==========\n",
      "Iter: 15\n",
      "Best pair: ('s', 'u')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 's', '</w>', 're', 'm', 'o', 'v', 'al', 'f', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 'd</w>', 'l', 'd', '.', 'p', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'i', 'e</w>', 'th', 'su', 'b', 'en', 'w', 'or', 'k', ',</w>', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 112\n",
      "==========\n",
      "Iter: 16\n",
      "Best pair: ('e', 'd</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 's', '</w>', 're', 'm', 'o', 'v', 'al', 'f', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 'ed</w>', 'l', 'd', '.', 'p', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'd</w>', 'i', 'e</w>', 'th', 'su', 'b', 'en', 'w', 'or', 'k', ',</w>', 'z', '<', '>', '2', '/', 'x', '≡', ';', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 113\n",
      "==========\n",
      "Iter: 17\n",
      "Best pair: ('.', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 's', '</w>', 're', 'm', 'o', 'v', 'al', 'f', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 'ed</w>', 'l', 'd', '.</w>', 'p', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'd</w>', 'i', 'e</w>', 'th', 'su', 'b', 'en', 'w', 'or', 'k', ',</w>', 'z', '<', '>', '2', '/', 'x', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 114\n",
      "==========\n",
      "Iter: 18\n",
      "Best pair: ('a', 't')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 's', '</w>', 're', 'm', 'o', 'v', 'al', 'f', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'd</w>', 'i', 'e</w>', 'th', 'su', 'b', 'en', 'w', 'or', 'k', ',</w>', 'z', '<', '>', '2', '/', 'x', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 115\n",
      "==========\n",
      "Iter: 19\n",
      "Best pair: ('an', 'd</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 's', '</w>', 're', 'm', 'o', 'v', 'al', 'f', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'd</w>', 'i', 'e</w>', 'th', 'su', 'b', 'en', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '/', 'x', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 116\n",
      "==========\n",
      "Iter: 20\n",
      "Best pair: ('s', 't')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 're', 'm', 'o', 'v', 'al', 'f', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'd</w>', 'i', 'e</w>', 'th', 'su', 'b', 'en', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '/', 'x', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 117\n",
      "==========\n",
      "Iter: 21\n",
      "Best pair: ('y', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 're', 'm', 'o', 'v', 'al', 'f', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'd</w>', 'y</w>', 'i', 'e</w>', 'th', 'su', 'b', 'en', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '/', 'x', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 118\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 22\n",
      "Best pair: ('r', 'o')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 're', 'm', 'o', 'v', 'al', 'f', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'd</w>', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'en', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '/', 'x', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 119\n",
      "==========\n",
      "Iter: 23\n",
      "Best pair: ('in', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'f', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'd</w>', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'en', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '/', 'x', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 120\n",
      "==========\n",
      "Iter: 24\n",
      "Best pair: ('f', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'f</w>', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'd</w>', 'f', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'en', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '/', 'x', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 121\n",
      "==========\n",
      "Iter: 25\n",
      "Best pair: ('a', 'r')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'f</w>', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'd</w>', 'f', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'ar', 'en', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '/', 'x', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 122\n",
      "==========\n",
      "Iter: 26\n",
      "Best pair: ('o', 'f</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'of</w>', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'u', '-', 'n', 'j', 'd</w>', 'f', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'ar', 'en', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '/', 'f</w>', 'x', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 123\n",
      "==========\n",
      "Iter: 27\n",
      "Best pair: ('ti', 'on')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'of</w>', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'ar', 'en', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '/', 'f</w>', 'x', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 124\n",
      "==========\n",
      "Iter: 28\n",
      "Best pair: ('i', 'c')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'of</w>', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'ar', 'en', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '/', 'f</w>', 'x', 'ic', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 125\n",
      "==========\n",
      "Iter: 29\n",
      "Best pair: ('s', 'i')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'of</w>', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'ar', 'si', 'en', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '/', 'f</w>', 'x', 'ic', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 126\n",
      "==========\n",
      "Iter: 30\n",
      "Best pair: ('t', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'of</w>', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'ar', 'si', 'en', 't</w>', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '/', 'f</w>', 'x', 'ic', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 127\n",
      "==========\n",
      "Iter: 31\n",
      "Best pair: ('<', '/')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'of</w>', 'g', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'ar', 'si', 'en', 't</w>', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '</', 'f</w>', '/', 'x', 'ic', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 128\n",
      "==========\n",
      "Iter: 32\n",
      "Best pair: ('g', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'of</w>', 'g', 'g</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'ar', 'si', 'en', 't</w>', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '</', 'f</w>', '/', 'x', 'ic', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 129\n",
      "==========\n",
      "Iter: 33\n",
      "Best pair: ('e', 'l')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'of</w>', 'g', 'g</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'at', 'y', 'ti', 'r', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'ar', 'si', 'en', 't</w>', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '</', 'f</w>', '/', 'x', 'ic', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 130\n",
      "==========\n",
      "Iter: 34\n",
      "Best pair: ('t', 'o')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'of</w>', 'g', 'g</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'to', 'at', 'y', 'ti', 'r', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'ar', 'si', 'en', 't</w>', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '</', 'f</w>', '/', 'x', 'ic', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 131\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 35\n",
      "Best pair: ('in', 'g</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'to', 'at', 'y', 'ti', 'r', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'ar', 'si', 'en', 't</w>', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '</', 'f</w>', '/', 'x', 'ic', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 132\n",
      "==========\n",
      "Iter: 36\n",
      "Best pair: ('d', 'i')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'to', 'at', 'y', 'ti', 'r', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'ar', 'si', 'en', 't</w>', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 133\n",
      "==========\n",
      "Iter: 37\n",
      "Best pair: ('e', 's</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'to', 'at', 'y', 'ti', 'r', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'es</w>', 'ar', 'si', 'en', 't</w>', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 134\n",
      "==========\n",
      "Iter: 38\n",
      "Best pair: ('i', '>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'to', 'at', 'y', 'ti', 'r', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'su', 'b', 'es</w>', 'ar', 'si', 'en', 't</w>', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 135\n",
      "==========\n",
      "Iter: 39\n",
      "Best pair: ('su', 'b')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'to', 'at', 'y', 'ti', 'r', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'su', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 136\n",
      "==========\n",
      "Iter: 40\n",
      "Best pair: ('al', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'r', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'su', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 137\n",
      "==========\n",
      "Iter: 41\n",
      "Best pair: ('r', 'a')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion', 'u', '-', 'n', 'j', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'su', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 138\n",
      "==========\n",
      "Iter: 42\n",
      "Best pair: ('c', 'o')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion', 'u', '-', 'n', 'j', 'co', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'su', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 139\n",
      "==========\n",
      "Iter: 43\n",
      "Best pair: ('e', 'c')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion', 'u', '-', 'n', 'j', 'co', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'su', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 140\n",
      "==========\n",
      "Iter: 44\n",
      "Best pair: ('a', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion', 'u', '-', 'n', 'j', 'co', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', '>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'a</w>', 'su', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 141\n",
      "==========\n",
      "Iter: 45\n",
      "Best pair: ('sub', '>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion', 'u', '-', 'n', 'j', 'co', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'a</w>', 'su', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 142\n",
      "==========\n",
      "Iter: 46\n",
      "Best pair: ('i', 't')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion', 'u', '-', 'n', 'j', 'co', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'a</w>', 'su', 'it', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 143\n",
      "==========\n",
      "Iter: 47\n",
      "Best pair: ('tion', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'a</w>', 'su', 'it', '≡', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 144\n",
      "==========\n",
      "Iter: 48\n",
      "Best pair: ('or', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'a</w>', 'su', 'it', '≡', 'or</w>', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 145\n",
      "==========\n",
      "Iter: 49\n",
      "Best pair: ('a', 's</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'a</w>', 'su', 'it', '≡', 'or</w>', ';', '.', 'F', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', '0', '·', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 146\n",
      "==========\n",
      "Iter: 50\n",
      "Best pair: ('F', '-')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'a</w>', 'su', 'it', '≡', 'or</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', 'F', '0', '·', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 147\n",
      "==========\n",
      "Iter: 51\n",
      "Best pair: ('er', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'a</w>', 'su', 'it', '≡', 'or</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', 'F', '0', '·', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 148\n",
      "==========\n",
      "Iter: 52\n",
      "Best pair: ('e', 's')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'ro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'a</w>', 'su', 'it', '≡', 'or</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', 'F', '0', '·', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 149\n",
      "==========\n",
      "Iter: 53\n",
      "Best pair: ('p', 'ro')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'a</w>', 'su', 'it', '≡', 'or</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', 'F', '0', '·', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 150\n",
      "==========\n",
      "Iter: 54\n",
      "Best pair: ('to', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'or</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', 'F', '0', '·', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 151\n",
      "==========\n",
      "Iter: 55\n",
      "Best pair: ('s', 'p')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', 'F', '0', '·', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 152\n",
      "==========\n",
      "Iter: 56\n",
      "Best pair: ('su', 'p')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', 'F', '0', '·', 'sup', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 153\n",
      "==========\n",
      "Iter: 57\n",
      "Best pair: ('th', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 's', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', 'F', '0', '·', 'sup', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 154\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 58\n",
      "Best pair: ('a', 's')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', 'F', '0', '·', 'sup', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 155\n",
      "==========\n",
      "Iter: 59\n",
      "Best pair: ('a', 'c')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', 'F', '0', '·', 'sup', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 156\n",
      "==========\n",
      "Iter: 60\n",
      "Best pair: (')', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', ')', 'F', '0', '·', 'sup', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 157\n",
      "==========\n",
      "Iter: 61\n",
      "Best pair: ('w', 'i')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'wi', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', ')', 'F', '0', '·', 'sup', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 158\n",
      "==========\n",
      "Iter: 62\n",
      "Best pair: ('er', 'e</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'ere</w>', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'wi', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', ')', 'F', '0', '·', 'sup', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 159\n",
      "==========\n",
      "Iter: 63\n",
      "Best pair: ('e', 't')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'ere</w>', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'wi', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', ')', 'F', '0', '·', 'sup', '>', '8', '%', 'D', 'E', 'G', \"'\", 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z'])\n",
      "Number of tokens: 160\n",
      "==========\n",
      "Iter: 64\n",
      "Best pair: ('sup', '>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'tion', 'co', 'd</w>', 'f', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'ere</w>', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'wi', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', ')', 'F', '0', '·', 'sup>', '8', '%', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 161\n",
      "==========\n",
      "Iter: 65\n",
      "Best pair: ('u', 'l')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'tion', 'co', 'ul', 'd</w>', 'f', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'ere</w>', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'wi', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', ')', 'F', '0', '·', 'sup>', '8', '%', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 162\n",
      "==========\n",
      "Iter: 66\n",
      "Best pair: ('ti', 'v')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'ere</w>', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'wi', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', ')', 'F', '0', '·', 'sup>', '8', '%', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 163\n",
      "==========\n",
      "Iter: 67\n",
      "Best pair: ('F', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'ere</w>', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'wi', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 164\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 68\n",
      "Best pair: ('u', 'n')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'ere</w>', 'di', 'x', 'ic', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'wi', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 165\n",
      "==========\n",
      "Iter: 69\n",
      "Best pair: ('r', 'i')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'ere</w>', 'di', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'wi', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'T', 'W', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 166\n",
      "==========\n",
      "Iter: 70\n",
      "Best pair: ('T', 'h')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'ere</w>', 'di', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'wi', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'B', 'R', 'N', 'M', 'I', 'Th', 'W', 'T', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 167\n",
      "==========\n",
      "Iter: 71\n",
      "Best pair: ('u', 'r')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'ere</w>', 'di', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'wi', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'I', 'Th', 'W', 'T', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 168\n",
      "==========\n",
      "Iter: 72\n",
      "Best pair: ('w', 'ere</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'were</w>', 'di', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'wi', 'th</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'I', 'Th', 'W', 'T', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 169\n",
      "==========\n",
      "Iter: 73\n",
      "Best pair: ('wi', 'th</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'were</w>', 'di', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'with</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 170\n",
      "==========\n",
      "Iter: 74\n",
      "Best pair: ('en', 't')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'ent', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'were</w>', 'di', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'with</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 171\n",
      "==========\n",
      "Iter: 75\n",
      "Best pair: ('m', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'ent', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'with</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 172\n",
      "==========\n",
      "Iter: 76\n",
      "Best pair: ('o', 'l')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'ent', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'with</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 173\n",
      "==========\n",
      "Iter: 77\n",
      "Best pair: ('m', 'p')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'u', 's', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'ent', 'w', 'or', 'k', ',</w>', 'ac', 'z', 'and</w>', '<', 'sub>', '2', '</', 'f</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'with</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 174\n",
      "==========\n",
      "Iter: 78\n",
      "Best pair: ('u', 's')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'ti', 'ra', 'tion</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ac', 'z', 'and</w>', 'u', '<', 'sub>', '2', '</', 'f</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'with</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 175\n",
      "==========\n",
      "Iter: 79\n",
      "Best pair: ('ti', 'c')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'tion</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ac', 'z', 'and</w>', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'with</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 176\n",
      "==========\n",
      "Iter: 80\n",
      "Best pair: ('a', 'tion</w>')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ac', 'z', 'and</w>', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'with</w>', 'tion</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', 'i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 177\n",
      "==========\n",
      "Iter: 81\n",
      "Best pair: ('<', 'i>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ac', 'z', 'and</w>', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'with</w>', 'tion</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', 'i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 178\n",
      "==========\n",
      "Iter: 82\n",
      "Best pair: ('</', 'i>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ac', 'z', 'and</w>', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'with</w>', 'tion</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 178\n",
      "==========\n",
      "Iter: 83\n",
      "Best pair: ('on', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ac', 'z', 'and</w>', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'on</w>', 'with</w>', 'tion</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0', '·', 'sup>', '8', '%', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 179\n",
      "==========\n",
      "Iter: 84\n",
      "Best pair: ('0', '.')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ac', 'z', 'and</w>', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'on</w>', 'with</w>', 'tion</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0.', '·', 'sup>', '8', '%', '0', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 180\n",
      "==========\n",
      "Iter: 85\n",
      "Best pair: ('e', 'x')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'r', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ac', 'z', 'and</w>', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'it', '≡', 'sp', 'or</w>', 'on</w>', 'with</w>', 'tion</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0.', '·', 'sup>', '8', '%', '0', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 181\n",
      "==========\n",
      "Iter: 86\n",
      "Best pair: ('i', 'r')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'ir', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ac', 'z', 'and</w>', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'r', 'it', '≡', 'sp', 'or</w>', 'on</w>', 'with</w>', 'tion</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0.', '·', 'sup>', '8', '%', '0', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 182\n",
      "==========\n",
      "Iter: 87\n",
      "Best pair: ('e', 'v')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'ir', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ac', 'z', 'and</w>', 'ev', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'r', 'it', '≡', 'sp', 'or</w>', 'on</w>', 'with</w>', 'tion</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0.', '·', 'sup>', '8', '%', '0', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 183\n",
      "==========\n",
      "Iter: 88\n",
      "Best pair: ('l', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'ir', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ac', 'z', 'and</w>', 'ev', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', 'l</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'r', 'it', '≡', 'sp', 'or</w>', 'on</w>', 'with</w>', 'tion</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0.', '·', 'sup>', '8', '%', '0', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 184\n",
      "==========\n",
      "Iter: 89\n",
      "Best pair: ('c', 'h')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'ir', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ch', 'ac', 'z', 'and</w>', 'ev', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', 'l</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'r', 'it', '≡', 'sp', 'or</w>', 'on</w>', 'with</w>', 'tion</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0.', '·', 'sup>', '8', '%', '0', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 185\n",
      "==========\n",
      "Iter: 90\n",
      "Best pair: ('i', 's')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'ir', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ch', 'ac', 'z', 'and</w>', 'ev', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', 'l</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'r', 'it', '≡', 'sp', 'or</w>', 'is', 'on</w>', 'with</w>', 'tion</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0.', '·', 'sup>', '8', '%', '0', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 186\n",
      "==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 91\n",
      "Best pair: ('C', '-')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'c', 'on', 'a', 'an', 's</w>', 'h', 'as</w>', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'ir', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ch', 'ac', 'z', 'and</w>', 'ev', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', 'l</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'r', 'it', '≡', 'sp', 'or</w>', 'is', 'on</w>', 'with</w>', 'tion</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0.', '·', 'sup>', '8', '%', '0', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'C-', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 187\n",
      "==========\n",
      "Iter: 92\n",
      "Best pair: ('c', 'on')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'con', 'a', 'an', 's</w>', 'h', 'as</w>', 'c', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'ar', 'si', 'en', 't</w>', 'ir', 'on', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ch', 'ac', 'z', 'and</w>', 'ev', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', 'l</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'r', 'it', '≡', 'sp', 'or</w>', 'is', 'on</w>', 'with</w>', 'tion</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0.', '·', 'sup>', '8', '%', '0', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'C-', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 188\n",
      "==========\n",
      "Iter: 93\n",
      "Best pair: ('at', '</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'con', 'a', 'an', 's</w>', 'h', 'as</w>', 'c', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'at</w>', 'ar', 'si', 'en', 't</w>', 'ir', 'on', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ch', 'ac', 'z', 'and</w>', 'ev', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', 'l</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'r', 'it', '≡', 'sp', 'or</w>', 'is', 'on</w>', 'with</w>', 'tion</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0.', '·', 'sup>', '8', '%', '0', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'C-', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 189\n",
      "==========\n",
      "Iter: 94\n",
      "Best pair: ('f', 'or</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'con', 'a', 'an', 's</w>', 'h', 'as</w>', 'c', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'at</w>', 'ar', 'si', 'en', 't</w>', 'ir', 'on', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ch', 'ac', 'z', 'and</w>', 'ev', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', 'l</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'r', 'it', '≡', 'sp', 'or</w>', 'is', 'on</w>', 'with</w>', 'tion</w>', 'for</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'Th', 'W', 'T', ')', 'F', '0.', '·', 'sup>', '8', '%', '0', 'F</w>', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'C-', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 190\n",
      "==========\n",
      "Iter: 95\n",
      "Best pair: ('Th', 'e</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'con', 'a', 'an', 's</w>', 'h', 'as</w>', 'c', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'at</w>', 'ar', 'si', 'en', 't</w>', 'ir', 'on', 'ent', 'w', 'or', 'k', ',</w>', 's', 'ch', 'ac', 'z', 'and</w>', 'ev', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', 'l</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'r', 'it', '≡', 'sp', 'or</w>', 'is', 'on</w>', 'with</w>', 'tion</w>', 'for</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'The</w>', 'W', 'T', ')', 'F', '0.', '·', 'sup>', '8', '%', '0', 'F</w>', 'Th', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'C-', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 191\n",
      "==========\n",
      "Iter: 96\n",
      "Best pair: ('i', 's</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'con', 'a', 'an', 's</w>', 'h', 'as</w>', 'c', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'at</w>', 'ar', 'si', 'en', 't</w>', 'ir', 'on', 'ent', 'is</w>', 'w', 'or', 'k', ',</w>', 's', 'ch', 'ac', 'z', 'and</w>', 'ev', 'u', 'ti', '<', 'sub>', '2', '</', 'f</w>', 'l</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'r', 'it', '≡', 'sp', 'or</w>', 'is', 'on</w>', 'with</w>', 'tion</w>', 'for</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'The</w>', 'W', 'T', ')', 'F', '0.', '·', 'sup>', '8', '%', '0', 'F</w>', 'Th', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'C-', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 192\n",
      "==========\n",
      "Iter: 97\n",
      "Best pair: ('<', 'sub>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'con', 'a', 'an', 's</w>', 'h', 'as</w>', 'c', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'at</w>', 'ar', 'si', 'en', 't</w>', 'ir', 'on', 'ent', 'is</w>', 'w', 'or', 'k', ',</w>', 's', 'ch', 'ac', 'z', 'and</w>', 'ev', 'u', 'ti', '<sub>', '2', '</', 'sub>', 'f</w>', 'l</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'r', 'it', '≡', 'sp', 'or</w>', 'is', 'on</w>', 'with</w>', 'tion</w>', 'for</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'The</w>', 'W', 'T', ')', 'F', '0.', '·', '<', 'sup>', '8', '%', '0', 'F</w>', 'Th', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'C-', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 193\n",
      "==========\n",
      "Iter: 98\n",
      "Best pair: ('</', 'sub>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'con', 'a', 'an', 's</w>', 'h', 'as</w>', 'c', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'at</w>', 'ar', 'si', 'en', 't</w>', 'ir', 'on', 'ent', 'is</w>', 'w', 'or', 'k', ',</w>', 's', 'ch', 'ac', 'z', 'and</w>', 'ev', 'u', 'ti', '<sub>', '2', '</sub>', 'f</w>', 'l</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'r', 'it', '≡', 'sp', 'or</w>', 'is', 'on</w>', 'with</w>', 'tion</w>', 'for</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'The</w>', 'W', 'T', ')', 'F', '0.', '·', '<', 'sup>', '</', '8', '%', '0', 'F</w>', 'Th', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'C-', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 193\n",
      "==========\n",
      "Iter: 99\n",
      "Best pair: ('w', 'as</w>')\n",
      "All tokens: dict_keys(['the</w>', 'in', 't', 'er', 'e', 'st', '</w>', 'in</w>', 're', 'm', 'o', 'v', 'al</w>', 'of</w>', 'g', 'ing</w>', 'con', 'a', 'an', 's</w>', 'h', 'as</w>', 'c', 'as', 'ed</w>', 'l', 'd', 'ec', '.</w>', 'p', 'to', 'at', 'al', 'y', 'tic', 'ra', 'ation</w>', 'us', '-', 'n', 'et', 'j', 'un', 'tion', 'co', 'ul', 'd</w>', 'f', 'tiv', 'el', 'y</w>', 'pro', 'i', 'e</w>', 'th', 'es', 'sub', 'es</w>', 'at</w>', 'ar', 'si', 'en', 't</w>', 'ir', 'on', 'ent', 'is</w>', 'w', 'or', 'k', ',</w>', 's', 'ch', 'ac', 'z', 'and</w>', 'ev', 'u', 'ti', '<sub>', '2', '</sub>', 'f</w>', 'l</w>', '/', 'mp', 'were</w>', 'di', 'm</w>', 'x', 'ic', 'ri', 'b', 'to</w>', 'a</w>', 'su', 'r', 'it', '≡', 'sp', 'or</w>', 'is', 'on</w>', 'with</w>', 'tion</w>', 'was</w>', 'for</w>', ';', '.', 'F-', 'q', '(', 'U', 'P', 'S', ')</w>', 'ro', 'A', 'g</w>', 'C', 'ex', 'er</w>', 'ol', 'H', ',', '5', '9', '4', '1', '3', '7', '6', 'O', 'ur', 'B', 'R', 'N', 'M', 'th</w>', 'wi', 'I', 'The</w>', 'W', 'T', ')', 'F', '0.', '·', '<', 'sup>', '</', '8', '%', '0', 'F</w>', 'Th', 'D', 'E', 'G', \"'\", 'sup', 'L', 'V', 'J', '∑', ':', 'K', 'μ', '×', '\"', '<i>', '</i>', 'X', 'Y', 'Q', '=', 'C-', 'ere</w>', '≥', 'α', '[', ']', '°', '{', '}', 'η', 'κ', '+', '®', '±', '≤', 'β', 'Z', '>'])\n",
      "Number of tokens: 194\n",
      "==========\n",
      "['ation</w>', '</sub>', 'were</w>', 'with</w>', '<sub>', 'tion</w>', 'the</w>', 'and</w>', 'ing</w>', 'tion', 'sup>', '</i>', 'for</w>', 'The</w>', 'was</w>', 'ere</w>', 'ed</w>', 'in</w>', 'of</w>', 'es</w>', 'al</w>', 'er</w>', 'pro', 'to</w>', 'tiv', 'ent', 'tic', '<i>', 'on</w>', 'con', 'at</w>', 'is</w>', 'as</w>', 'or</w>', 'th</w>', 'sub', 'sup', 'e</w>', ',</w>', 're', 'en', 's</w>', 'er', '.</w>', 'an', 'in', 'or', 'st', 'y</w>', 'ar', 'at', 'th', 'al', 'ic', 'si', 't</w>', 'ti', 'el', 'di', 'ro', 'ra', 'co', 'on', 'ec', 'a</w>', 'it', 'F-', 'es', 'd</w>', 'sp', 'as', 'ac', ')</w>', 'et', 'ul', 'F</w>', 'un', 'ri', 'ur', 'm</w>', 'ol', 'mp', 'us', '0.', 'ex', 'su', 'ir', 'ev', 'l</w>', 'ch', 'is', 'C-', 'to', '</', 'g</w>', 'wi', 'Th', 'f</w>', '</w>', 'l', 'o', 'i', 'm', 'e', 'a', 'p', 'c', 's', 't', 'd', 'g', 'u', 'f', 'h', 'b', 'y', 'v', '-', 'w', 'n', 'A', '1', '(', 'P', 'S', '2', 'C', '.', '0', 'R', 'F', 'r', ')', 'M', '3', '5', '4', 'I', 'k', 'T', '9', 'E', '8', '/', 'D', '7', 'x', 'B', '<', 'G', '%', '6', 'z', 'O', 'H', 'L', ',', '[', ']', 'N', 'U', 'q', 'W', '=', 'V', ':', 'Y', 'j', '≥', \"'\", '+', 'K', '\"', ';', 'X', 'μ', 'β', '±', '·', 'Q', 'α', '°', 'J', '>', '{', '}', 'η', 'κ', 'Z', '≡', '∑', '×', '®', '≤']\n",
      "Tokenizing word: mountains</w>...\n",
      "Tokenizating of the unknown word:\n",
      "['m', 'o', 'un', 't', 'a', 'in', 's</w>']\n",
      "Tokenizing word: Ilikeeatingapples!</w>...\n",
      "Tokenizating of the unknown word:\n",
      "['I', 'l', 'i', 'k', 'e', 'e', 'at', 'in', 'g', 'a', 'p', 'p', 'l', 'es', '</', 'w', '>']\n"
     ]
    }
   ],
   "source": [
    "import re, collections\n",
    "\n",
    "def get_vocab(filename):\n",
    "    vocab = collections.defaultdict(int)\n",
    "    with open(filename, 'r', encoding='utf-8') as fhand:\n",
    "        for line in fhand:\n",
    "            words = line.strip().split()\n",
    "            for word in words:\n",
    "                vocab[' '.join(list(word)) + ' </w>'] += 1\n",
    "\n",
    "    return vocab\n",
    "\n",
    "def get_stats(vocab):\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out\n",
    "\n",
    "def get_tokens_from_vocab(vocab):\n",
    "    tokens_frequencies = collections.defaultdict(int)\n",
    "    vocab_tokenization = {}\n",
    "    for word, freq in vocab.items():\n",
    "        word_tokens = word.split()\n",
    "        for token in word_tokens:\n",
    "            tokens_frequencies[token] += freq\n",
    "        vocab_tokenization[''.join(word_tokens)] = word_tokens\n",
    "    return tokens_frequencies, vocab_tokenization\n",
    "\n",
    "def measure_token_length(token):\n",
    "    if token[-4:] == '</w>':\n",
    "        return len(token[:-4]) + 1\n",
    "    else:\n",
    "        return len(token)\n",
    "\n",
    "def tokenize_word(string, sorted_tokens, unknown_token='</u>'):\n",
    "    \n",
    "    if string == '':\n",
    "        return []\n",
    "    if sorted_tokens == []:\n",
    "        return [unknown_token]\n",
    "\n",
    "    string_tokens = []\n",
    "    for i in range(len(sorted_tokens)):\n",
    "        token = sorted_tokens[i]\n",
    "        token_reg = re.escape(token.replace('.', '[.]'))\n",
    "\n",
    "        matched_positions = [(m.start(0), m.end(0)) for m in re.finditer(token_reg, string)]\n",
    "        if len(matched_positions) == 0:\n",
    "            continue\n",
    "        substring_end_positions = [matched_position[0] for matched_position in matched_positions]\n",
    "\n",
    "        substring_start_position = 0\n",
    "        for substring_end_position in substring_end_positions:\n",
    "            substring = string[substring_start_position:substring_end_position]\n",
    "            string_tokens += tokenize_word(string=substring, sorted_tokens=sorted_tokens[i+1:], unknown_token=unknown_token)\n",
    "            string_tokens += [token]\n",
    "            substring_start_position = substring_end_position + len(token)\n",
    "        remaining_substring = string[substring_start_position:]\n",
    "        string_tokens += tokenize_word(string=remaining_substring, sorted_tokens=sorted_tokens[i+1:], unknown_token=unknown_token)\n",
    "        break\n",
    "    return string_tokens\n",
    "\n",
    "# vocab = {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w e s t </w>': 6, 'w i d e s t </w>': 3}\n",
    "#! wget http://www.gutenberg.org/cache/epub/16457/pg16457.txt\n",
    "#vocab = get_vocab('pg16457.txt')\n",
    "vocab = get_vocab('inputText.txt')\n",
    "\n",
    "print('==========')\n",
    "print('Tokens Before BPE')\n",
    "tokens_frequencies, vocab_tokenization = get_tokens_from_vocab(vocab)\n",
    "print('All tokens: {}'.format(tokens_frequencies.keys()))\n",
    "print('Number of tokens: {}'.format(len(tokens_frequencies.keys())))\n",
    "print('==========')\n",
    "\n",
    "num_merges = 100\n",
    "for i in range(num_merges):\n",
    "    pairs = get_stats(vocab)\n",
    "    if not pairs:\n",
    "        break\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    vocab = merge_vocab(best, vocab)\n",
    "    print('Iter: {}'.format(i))\n",
    "    print('Best pair: {}'.format(best))\n",
    "    tokens_frequencies, vocab_tokenization = get_tokens_from_vocab(vocab)\n",
    "    print('All tokens: {}'.format(tokens_frequencies.keys()))\n",
    "    print('Number of tokens: {}'.format(len(tokens_frequencies.keys())))\n",
    "    print('==========')\n",
    "\n",
    "# Let's check how tokenization will be for a known word\n",
    "word_given_known = 'mountains</w>'\n",
    "word_given_unknown = 'Ilikeeatingapples!</w>'\n",
    "\n",
    "sorted_tokens_tuple = sorted(tokens_frequencies.items(), key=lambda item: (measure_token_length(item[0]), item[1]), reverse=True)\n",
    "sorted_tokens = [token for (token, freq) in sorted_tokens_tuple]\n",
    "\n",
    "print(sorted_tokens)\n",
    "\n",
    "word_given = word_given_known \n",
    "\n",
    "print('Tokenizing word: {}...'.format(word_given))\n",
    "if word_given in vocab_tokenization:\n",
    "    print('Tokenization of the known word:')\n",
    "    print(vocab_tokenization[word_given])\n",
    "    print('Tokenization treating the known word as unknown:')\n",
    "    print(tokenize_word(string=word_given, sorted_tokens=sorted_tokens, unknown_token='</u>'))\n",
    "else:\n",
    "    print('Tokenizating of the unknown word:')\n",
    "    print(tokenize_word(string=word_given, sorted_tokens=sorted_tokens, unknown_token='</u>'))\n",
    "\n",
    "word_given = word_given_unknown \n",
    "\n",
    "print('Tokenizing word: {}...'.format(word_given))\n",
    "if word_given in vocab_tokenization:\n",
    "    print('Tokenization of the known word:')\n",
    "    print(vocab_tokenization[word_given])\n",
    "    print('Tokenization treating the known word as unknown:')\n",
    "    print(tokenize_word(string=word_given, sorted_tokens=sorted_tokens, unknown_token='</u>'))\n",
    "else:\n",
    "    print('Tokenizating of the unknown word:')\n",
    "    print(tokenize_word(string=word_given, sorted_tokens=sorted_tokens, unknown_token='</u>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8c2adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10522/1005186977.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_containers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfirst_article\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle_containers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mcitation_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_article\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'docsum-wrap'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'result-actions-bar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'content'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xlsxwriter\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "URL = 'https://pubmed.ncbi.nlm.nih.gov/?term=COVID+19&size=200'\n",
    "response = requests.get(URL)\n",
    "\n",
    "print(response)\n",
    "\n",
    "html_soup = BeautifulSoup(response.text, 'html5lib')\n",
    "article_containers = html_soup.find_all('article', class_ = 'labs-full-docsum')\n",
    "print(article_containers)\n",
    "\n",
    "first_article = article_containers[0]\n",
    "citation_text = first_article.find('div', class_ = 'docsum-wrap').find('div', class_ = 'result-actions-bar').div.div.find('div', class_ = 'content').div.div.text\n",
    "\n",
    "print(citation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35ebb3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'pubmed_id': '35252546', 'abstract': 'The aim of the current study is to evaluate Virginia fanpetals silage based on an apparent digestibility and palatability test performed on six adult rams. Alfalfa silage was used as standard forage for comparison. Virginia fanpetals samples were harvested in the bud-formation stage and alfalfa samples were harvested in the late bud stage. Virginia fanpetals silage had a crude protein (CP) content of 176\\u202fg\\u202fkg ', 'conclusions': None, 'results': None}]\n"
     ]
    }
   ],
   "source": [
    "#!pip install pymed\n",
    "from pymed import PubMed\n",
    "import pandas as pd\n",
    "pubmed = PubMed(tool=\"PubMedSearcher\", email=\"myemail@ccc.com\")\n",
    "\n",
    "## PUT YOUR SEARCH TERM HERE ##\n",
    "search_term = \"fever\"\n",
    "TERM = 'for DM it was 0.707, for organic matter (OM) it was 0.724, for CP it was 0.861, and for NDF it was 0.609. In comparison with alfalfa silage, Virginia fanpetals silage was characterized by higher apparent digestibility of nutrients, but a significant difference was noted only for CP. The voluntary intake of Virginia fanpetals silage was significantly higher than that of alfalfa silage (1427.4 vs. 954g DM). The greatest differences in voluntary intake were observed 0-2 and 8-12h after feeding. Virginia fanpetals silage had a chemical composition similar to that of alfalfa, but it was characterized by a more desirable fermentation pattern and higher digestibility, and it was more willingly consumed by rams'\n",
    "\n",
    "results = pubmed.query(TERM, max_results=5000000000)\n",
    "articleList = []\n",
    "articleInfo = []\n",
    "\n",
    "for article in results:\n",
    "# Print the type of object we've found (can be either PubMedBookArticle or PubMedArticle).\n",
    "# We need to convert it to dictionary with available function\n",
    "    articleDict = article.toDict()\n",
    "    articleList.append(articleDict)\n",
    "\n",
    "# Generate list of dict records which will hold all article details that could be fetch from PUBMED API\n",
    "for article in articleList:\n",
    "#Sometimes article['pubmed_id'] contains list separated with comma - take first pubmedId in that list - thats article pubmedId\n",
    "    pubmedId = article['pubmed_id'].partition('\\n')[0]\n",
    "    # Append article info to dictionary \n",
    "    articleInfo.append({u'pubmed_id':pubmedId,\n",
    "                       #u'title':article['title'],\n",
    "                       #u'keywords':article['keywords'],\n",
    "                       #u'journal':article['journal'],\n",
    "                       u'abstract':article['abstract'],\n",
    "                       u'conclusions':article['conclusions'],\n",
    "                       #u'methods':article['methods'],\n",
    "                       u'results': article['results'],\n",
    "                       #u'copyrights':article['copyrights'],\n",
    "                       #u'doi':article['doi'],\n",
    "                       #u'publication_date':article['publication_date'], \n",
    "                       #u'authors':article['authors']\n",
    "                       })\n",
    "print(articleInfo)\n",
    "# Generate Pandas DataFrame from list of dictionaries\n",
    "#articlesPD = pd.DataFrame.from_dict(articleInfo)\n",
    "#export_csv = df.to_csv (r'C:\\Users\\YourUsernam\\Desktop\\export_dataframe.csv', index = None, header=True) \n",
    "\n",
    "#Print first 10 rows of dataframe\n",
    "#print(articlesPD.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0154fa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting 100 publications containing for DM it was 0.707, for organic matter (OM) it was 0.724, for CP it was 0.861, and for NDF it was 0.609. In comparison with alfalfa silage, Virginia fanpetals silage was characterized by higher apparent digestibility of nutrients, but a significant difference was noted only for CP. The voluntary intake of Virginia fanpetals silage was significantly higher than that of alfalfa silage (1427.4 vs. 954g DM). The greatest differences in voluntary intake were observed 0-2 and 8-12h after feeding. Virginia fanpetals silage had a chemical composition similar to that of alfalfa, but it was characterized by a more desirable fermentation pattern and higher digestibility, and it was more willingly consumed by rams...\n",
      "Total number of publications containing for DM it was 0.707, for organic matter (OM) it was 0.724, for CP it was 0.861, and for NDF it was 0.609. In comparison with alfalfa silage, Virginia fanpetals silage was characterized by higher apparent digestibility of nutrients, but a significant difference was noted only for CP. The voluntary intake of Virginia fanpetals silage was significantly higher than that of alfalfa silage (1427.4 vs. 954g DM). The greatest differences in voluntary intake were observed 0-2 and 8-12h after feeding. Virginia fanpetals silage had a chemical composition similar to that of alfalfa, but it was characterized by a more desirable fermentation pattern and higher digestibility, and it was more willingly consumed by rams: 1\n",
      "Authors: The aim of the current study is to evaluate Virginia fanpetals silage based on an apparent digestibility and palatability test performed on six adult rams. Alfalfa silage was used as standard forage for comparison. Virginia fanpetals samples were harvested in the bud-formation stage and alfalfa samples were harvested in the late bud stage. Virginia fanpetals silage had a crude protein (CP) content of 176gkg - 1 dry matter (DM), a neutral detergent fiber (NDF) content of 378gkg - 1 DM, and a lignin content of 42.8gkg - 1 DM. Virginia fanpetals silage had higher acidity (pH of 4.30) and was characterized by intense lactic acid fermentation compared with alfalfa silage (80% vs. 51% of the total acids). The digestibility coefficient of Virginia fanpetals silage was as follows: for DM it was 0.707, for organic matter (OM) it was 0.724, for CP it was 0.861, and for NDF it was 0.609. In comparison with alfalfa silage, Virginia fanpetals silage was characterized by higher apparent digestibility of nutrients, but a significant difference was noted only for CP. The voluntary intake of Virginia fanpetals silage was significantly higher than that of alfalfa silage (1427.4 vs. 954g DM). The greatest differences in voluntary intake were observed 0-2 and 8-12h after feeding. Virginia fanpetals silage had a chemical composition similar to that of alfalfa, but it was characterized by a more desirable fermentation pattern and higher digestibility, and it was more willingly consumed by rams. The present findings indicate that Virginia fanpetals silage can be fed to sheep.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# numpy and biopython are required -- pip install numpy biopython\n",
    "\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "\n",
    "MAX_COUNT = 100\n",
    "TERM = 'for DM it was 0.707, for organic matter (OM) it was 0.724, for CP it was 0.861, and for NDF it was 0.609. In comparison with alfalfa silage, Virginia fanpetals silage was characterized by higher apparent digestibility of nutrients, but a significant difference was noted only for CP. The voluntary intake of Virginia fanpetals silage was significantly higher than that of alfalfa silage (1427.4 vs. 954g DM). The greatest differences in voluntary intake were observed 0-2 and 8-12h after feeding. Virginia fanpetals silage had a chemical composition similar to that of alfalfa, but it was characterized by a more desirable fermentation pattern and higher digestibility, and it was more willingly consumed by rams'\n",
    "\n",
    "print('Getting {0} publications containing {1}...'.format(MAX_COUNT, TERM))\n",
    "Entrez.email = 'A.N.Other@example.com'\n",
    "h = Entrez.esearch(db='pubmed', retmax=MAX_COUNT, term=TERM)\n",
    "result = Entrez.read(h)\n",
    "print('Total number of publications containing {0}: {1}'.format(TERM, result['Count']))\n",
    "ids = result['IdList']\n",
    "h = Entrez.efetch(db='pubmed', id=ids, rettype='medline', retmode='text')\n",
    "records = Medline.parse(h)\n",
    "\n",
    "authors = []\n",
    "for record in records:\n",
    "    au = record.get('AB', '?')\n",
    "    #for a in au: \n",
    "        #if a not in authors:\n",
    "    authors.append(au)\n",
    "    authors.sort()\n",
    "print('Authors: {0}'.format(', '.join(authors)))\n",
    "    #authors.append(record)\n",
    "    \n",
    "#print(authors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
